import streamlit as st
from PIL import Image
import pytesseract
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM


# ==============================
# STREAMLIT CONFIG
# ==============================
st.set_page_config(
    page_title="OCR + Chatbot Ti·∫øng Vi·ªát (B·∫£n Nh·∫π)",
    layout="wide"
)

st.title("üìÑ OCR + ü§ñ Chatbot Ti·∫øng Vi·ªát ‚Äì B·∫£n Nh·∫π (Streamlit Cloud)")


# ==============================
# LOAD SMALL LLM (VERY LIGHT)
# ==============================
@st.cache_resource
def load_llm():
    model_name = "VietAI/gpt-j-6B-vi-lite"  # model distill nh·ªè

    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # Ch·∫°y CPU (Streamlit Cloud kh√¥ng c√≥ GPU)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.float32,
        low_cpu_mem_usage=True
    )

    return tokenizer, model


tokenizer, model = load_llm()


# ==============================
# FUNCTION: QA FROM OCR
# ==============================
def ask_ai(ocr_text, question):

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω AI hi·ªÉu ti·∫øng Vi·ªát.

D∆∞·ªõi ƒë√¢y l√† vƒÉn b·∫£n OCR tr√≠ch t·ª´ ·∫£nh:

{ocr_text}

C√¢u h·ªèi: {question}

H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† ch√≠nh x√°c.
"""

    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(
        **inputs,
        max_new_tokens=150,
        do_sample=False,
        temperature=0.3
    )

    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return answer


# ==============================
# UI
# ==============================
uploaded = st.file_uploader("üì§ Ch·ªçn ·∫£nh (jpg/png)‚Ä¶", type=["jpg", "jpeg", "png"])

if "ocr" not in st.session_state:
    st.session_state.ocr = ""


# ------------------------------
# OCR VIA TESSERACT (LIGHT)
# ------------------------------
if uploaded:
    img = Image.open(uploaded)
    st.image(img, use_column_width=True)

    if st.button("üîç Ch·∫°y OCR"):
        with st.spinner("ƒêang ch·∫°y OCR‚Ä¶"):
            text = pytesseract.image_to_string(img, lang="vie")
            st.session_state.ocr = text

        st.success("Ho√†n t·∫•t OCR!")
        st.text_area("üìå VƒÉn b·∫£n OCR:", text, height=200)


# ------------------------------
# CHATBOT
# ------------------------------
st.subheader("üí¨ H·ªèi AI d·ª±a tr√™n OCR")

if not st.session_state.ocr:
    st.info("H√£y upload ·∫£nh v√† ch·∫°y OCR tr∆∞·ªõc.")
else:
    q = st.text_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")

    if st.button("ü§ñ Tr·∫£ l·ªùi"):
        with st.spinner("AI ƒëang tr·∫£ l·ªùi‚Ä¶"):
            answer = ask_ai(st.session_state.ocr, q)

        st.write("### üß† Tr·∫£ l·ªùi:")
        st.write(answer)
