import streamlit as st
from PIL import Image
import numpy as np
from paddleocr import PaddleOCR
from llama_cpp import Llama

# ===========================
# STREAMLIT PAGE CONFIG
# ===========================
st.set_page_config(
    page_title="OCR + LLM Chatbot (HF Spaces)",
    layout="wide"
)

st.title("ğŸ“„ OCR + ğŸ¤– Chatbot (LLM Offline â€“ HuggingFace Spaces)")

# ===========================
# LOAD MODELS WITH CACHE
# ===========================
@st.cache_resource
def load_ocr_model():
    return PaddleOCR(use_angle_cls=True, lang="vi")

@st.cache_resource
def load_llm_model():
    return Llama(
        model_path="models/Phi-3-mini-4k-instruct.Q4_K_M.gguf",  
        n_ctx=2048,
        n_threads=4,   # HF Spaces CPU typically = 2â€“4 threads
        verbose=False
    )

ocr = load_ocr_model()
llm = load_llm_model()


# ===========================
# FRONTEND â€“ UPLOAD IMAGE
# ===========================
uploaded_file = st.file_uploader(
    "ğŸ“¤ Táº£i áº£nh hÃ³a Ä‘Æ¡n / giáº¥y tá» (jpg, png)", 
    type=["jpg", "jpeg", "png"]
)

if "ocr_text" not in st.session_state:
    st.session_state.ocr_text = ""


# ===========================
# OCR PROCESSING
# ===========================
if uploaded_file:
    img = Image.open(uploaded_file)
    st.image(img, caption="ğŸ–¼ áº¢nh Ä‘Ã£ upload", use_column_width=True)

    st.write("ğŸ” Äang cháº¡y OCR... vui lÃ²ng chá»")

    result = ocr.ocr(np.array(img), cls=True)

    text = "\n".join([line[1][0] for line in result[0]])
    st.session_state.ocr_text = text

    st.subheader("ğŸ“Œ Káº¿t quáº£ OCR:")
    st.write(text)

    st.divider()


# ===========================
# CHATBOT QA USING OFFLINE LLM
# ===========================
if st.session_state.ocr_text:
    st.subheader("ğŸ’¬ Há»i AI vá» ná»™i dung OCR")

    query = st.text_input("Nháº­p cÃ¢u há»i:")

    if query:
        prompt = f"""
Báº¡n lÃ  trá»£ lÃ½ AI thÃ´ng minh.
DÆ°á»›i Ä‘Ã¢y lÃ  vÄƒn báº£n OCR trÃ­ch tá»« áº£nh:

{text}

CÃ¢u há»i: {query}

HÃ£y tráº£ lá»i chi tiáº¿t vÃ  chÃ­nh xÃ¡c.
"""

        output = llm(
            prompt,
            max_tokens=256,
            temperature=0.1
        )

        answer = output["choices"][0]["text"]

        st.subheader("ğŸ¤– Tráº£ lá»i:")
        st.write(answer)

else:
    st.info("â¬†ï¸ HÃ£y upload áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u OCR.")
