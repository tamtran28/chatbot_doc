import streamlit as st
from PIL import Image
import pytesseract
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# =========================================
# STREAMLIT CONFIG
# =========================================
st.set_page_config(page_title="OCR + Chatbot Ti·∫øng Vi·ªát", layout="wide")
st.title("üìÑ OCR + ü§ñ Chatbot Ti·∫øng Vi·ªát (B·∫£n si√™u nh·∫π - Streamlit Cloud)")


# =========================================
# LOAD SMALL LLM (FASTEST FOR STREAMLIT)
# =========================================
@st.cache_resource
def load_llm():
    model_name = "vinai/gpt2-vi-small"  # model Vi·ªát h√≥a r·∫•t nh·∫π

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.float32
    )

    return tokenizer, model


tokenizer, model = load_llm()


# =========================================
# AI ANSWER FUNCTION
# =========================================
def ask_ai(ocr_text, question):
    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω AI gi·ªèi ti·∫øng Vi·ªát.

VƒÉn b·∫£n OCR t·ª´ ·∫£nh:

{ocr_text}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi:
    """

    inputs = tokenizer(prompt, return_tensors="pt")

    outputs = model.generate(
        **inputs,
        max_new_tokens=100,
        do_sample=True,
        top_p=0.9,
        temperature=0.7,
        pad_token_id=tokenizer.eos_token_id
    )

    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return answer


# =========================================
# UI
# =========================================
uploaded_image = st.file_uploader("üì§ Ch·ªçn ·∫£nh (jpg/png)‚Ä¶", type=["jpg", "jpeg", "png"])

if "ocr" not in st.session_state:
    st.session_state.ocr = ""


# =========================================
# OCR USING TESSERACT (LIGHT & CLOUD SAFE)
# =========================================
if uploaded_image:
    img = Image.open(uploaded_image)
    st.image(img, caption="·∫¢nh ƒë√£ t·∫£i", use_column_width=True)

    if st.button("üîç Ch·∫°y OCR"):
        with st.spinner("ƒêang x·ª≠ l√Ω OCR‚Ä¶"):
            text = pytesseract.image_to_string(img, lang="vie")
            st.session_state.ocr = text

        st.success("OCR ho√†n t·∫•t!")
        st.text_area("üìå VƒÉn b·∫£n OCR:", st.session_state.ocr, height=200)


# =========================================
# QA SECTION
# =========================================
st.subheader("üí¨ H·ªèi chatbot d·ª±a tr√™n vƒÉn b·∫£n OCR")

if not st.session_state.ocr:
    st.info("H√£y upload ·∫£nh v√† ch·∫°y OCR tr∆∞·ªõc.")
else:
    q = st.text_input("Nh·∫≠p c√¢u h·ªèi:")

    if st.button("ü§ñ Tr·∫£ l·ªùi"):
        with st.spinner("AI ƒëang x·ª≠ l√Ω‚Ä¶"):
            answer = ask_ai(st.session_state.ocr, q)
        st.write("### üß† Tr·∫£ l·ªùi:")
        st.write(answer)
