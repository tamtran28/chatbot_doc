import streamlit as st
import pytesseract
from PIL import Image
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM


# =====================================================
# STREAMLIT CONFIG
# =====================================================
st.set_page_config(
    page_title="OCR + Chatbot Ti·∫øng Vi·ªát (Streamlit Cloud)",
    layout="wide"
)

st.title("üìÑ OCR + ü§ñ Chatbot Ti·∫øng Vi·ªát (Streamlit Cloud ‚Äì CPU)")


# =====================================================
# LOAD LLM: Qwen2.5-0.5B-Instruct (CH·∫†Y ƒê∆Ø·ª¢C TR√äN CLOUD)
# =====================================================
@st.cache_resource
def load_llm():
    model_name = "Qwen/Qwen2.5-0.5B-Instruct"

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="cpu",
        torch_dtype=torch.float32
    )

    return tokenizer, model


tokenizer, model = load_llm()


# =====================================================
# FUNCTION: GENERATE ANSWER
# =====================================================
def ask_ai(ocr_text, question):

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω AI ti·∫øng Vi·ªát.

VƒÉn b·∫£n OCR ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ h√¨nh ·∫£nh:

{ocr_text}

C√¢u h·ªèi: {question}

H√£y tr·∫£ l·ªùi ch√≠nh x√°c v√† d·ªÖ hi·ªÉu.
"""

    inputs = tokenizer(prompt, return_tensors="pt")

    outputs = model.generate(
        **inputs,
        max_new_tokens=200,
        do_sample=False,
        temperature=0.2,
        pad_token_id=tokenizer.eos_token_id
    )

    return tokenizer.decode(outputs[0], skip_special_tokens=True)


# =====================================================
# UI
# =====================================================

uploaded = st.file_uploader("üì§ T·∫£i ·∫£nh (jpg/png)‚Ä¶", type=["jpg", "jpeg", "png"])

if "ocr" not in st.session_state:
    st.session_state.ocr = ""


# -----------------------------
# OCR BLOCK (TESSERACT)
# -----------------------------
if uploaded:
    img = Image.open(uploaded)
    st.image(img, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_column_width=True)

    if st.button("üîç Ch·∫°y OCR"):
        with st.spinner("ƒêang ch·∫°y OCR‚Ä¶"):
            text = pytesseract.image_to_string(img, lang="vie")
            st.session_state.ocr = text

        st.success("OCR ho√†n t·∫•t!")
        st.text_area("üìå VƒÉn b·∫£n OCR:", text, height=200)


# -----------------------------
# CHATBOT BLOCK
# -----------------------------
st.subheader("üí¨ Chatbot h·ªèi ƒë√°p d·ª±a tr√™n n·ªôi dung OCR")

if not st.session_state.ocr:
    st.info("‚ö†Ô∏è H√£y t·∫£i ·∫£nh v√† ch·∫°y OCR tr∆∞·ªõc.")
else:
    q = st.text_input("Nh·∫≠p c√¢u h·ªèi:")

    if st.button("ü§ñ Tr·∫£ l·ªùi"):
        with st.spinner("AI ƒëang x·ª≠ l√Ω‚Ä¶"):
            answer = ask_ai(st.session_state.ocr, q)

        st.write("### üß† Tr·∫£ l·ªùi:")
        st.write(answer)
